{
  "resumeTitle": {
    "title": "Yoo Ho In"
  },
  "information": {
    "name": "유호인",
    "contact": [
      {
        "id": 0,
        "name": "Email",
        "href": "mailto:ghdls3070@naver.com",
        "isEmail": true
      },
      {
        "id": 1,
        "name": "GitHub",
        "href": "https://github.com/hoinynote",
        "isEmail": false
      }
    ],
    "intro": [
      {
        "id": 1,
        "title": "데이터의 흐름을 설계하는 엔지니어",
        "description": "산업정보시스템공학을 전공하며 시스템의 비효율을 개선하는 최적화 사고를 길렀습니다. 복잡한 공정 데이터를 다루며 데이터의 정합성이 의사결정에 미치는 치명적인 영향을 체감했고, 이를 계기로 신뢰할 수 있는 데이터 파이프라인을 구축하는 데이터 엔지니어링에 매료되었습니다."
      },
      {
        "id": 2,
        "title": "실무 중심의 문제 해결 경험",
        "description": "Microsoft Data School 1기를 수료하며 Azure 클라우드 환경에서 End-to-End 데이터 파이프라인을 구축했습니다. 정형/비정형 데이터 수집부터 Data Lake 적재, 그리고 분석을 위한 Mart 구성까지의 전 과정을 직접 수행하며 기술적 단단함을 쌓았습니다. 특히 대용량 데이터 처리 과정에서 발생하는 지연 문제를 파티셔닝과 인덱싱 전략으로 해결하며 성능 최적화의 중요성을 배웠습니다."
      },
      {
        "id": 3,
        "title": "함께 성장하는 협업의 가치",
        "description": "엔지니어링은 혼자 하는 것이 아니라 동료와 함께 시스템을 만들어가는 과정이라 생각합니다. 복잡한 로직일수록 명료한 문서화를 통해 팀원들과 지식을 공유하려 노력합니다. '내 코드가 동료의 시간을 아껴줄 수 있는가?'를 항상 고민하며, 유지보수가 쉬운 간결한 코드를 작성하는 것을 목표로 합니다."
      }
    ],
    "markdown": "" 
  },
  "workExperience": [],
  "project": [
    {
      "id": 6,
      "name": "AI 수능 영어 학습 플랫폼 '메기스터디'",
      "description": "교육 플랫폼의 파편화된 데이터를 통합하여 데이터 사일로 문제를 해결하고, 이탈 위험군을 조기에 감지할 수 있는 분석 환경을 구축한 프로젝트입니다.",
      "body": "### **1. 프로젝트 목표 및 해결 과제**\n\n기존 교육 서비스는 학습 데이터(DB), 결제 정보(API), 상담 내역(CSV)이 각기 다른 곳에 저장되어 학생의 상태를 종합적으로 파악하기 어려운 **데이터 사일로(Data Silo)** 문제가 심각했습니다. 이를 해결하기 위해 흩어진 데이터를 하나의 Data Lake로 통합하고, AI를 활용해 학생별 맞춤 피드백을 제공하는 분석 환경을 구축하는 것을 목표로 했습니다.\n\n### **2. 기술적 구현**\n\n- **Data Integration:** Azure Data Factory를 사용하여 SQL DB, REST API, Flat File 등 이종 데이터 소스를 Azure Data Lake Storage Gen2로 통합하는 파이프라인 구축\n- **Analytics Environment:** Azure Fabric과 Spark를 활용하여 대용량 학습 로그 데이터를 전처리하고, 분석용 Data Mart 구성\n- **AI Service:** Next.js 기반의 관리자 웹을 개발하여 시각화 차트를 제공하고, Azure OpenAI API를 연동하여 학생의 취약점에 대한 자동 피드백 생성 기능 구현\n\n### **3. 핵심 기여 및 트러블슈팅**\n\n**① 대용량 로그 조회 속도 저하 문제 해결 (Partitioning)**\n- **문제:** 하루 수백만 건씩 쌓이는 학습 로그 테이블의 크기가 커지면서, 특정 날짜의 데이터를 조회하는 쿼리 속도가 급격히 느려졌습니다.\n- **해결:** 데이터 적재 시 연/월/일(`YYYY/MM/DD`) 폴더 구조로 나누어 저장하는 **파티셔닝(Partitioning)** 전략을 적용했습니다. 이를 통해 쿼리 스캔 범위를 최소화하여 데이터 조회 성능을 약 **40% 개선**했습니다.\n\n**② 무중단 DB 마이그레이션 (Azure DMS)**\n- **문제:** 운영 중인 온프레미스 DB를 클라우드로 이관해야 했으나, 서비스 중단(Downtime)을 허용할 수 없는 상황이었습니다.\n- **해결:** **Azure Database Migration Service(DMS)**의 온라인 모드를 활용했습니다. 초기 적재(Full Load) 후 발생하는 데이터 변경분(CDC)을 실시간으로 동기화하는 방식을 적용하여, 서비스 중단 없이 안정적으로 데이터를 이관했습니다.\n\n**③ 풀스택 개발 주도**\n- 데이터 엔지니어링뿐만 아니라 **Next.js**와 **Recharts** 라이브러리를 활용해 백엔드 데이터를 직관적인 그래프로 표현하는 프론트엔드 개발을 전담하여, 데이터 활용성을 극대화했습니다.",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2025. 08", "2025. 09"],
      "stack": ["Azure OpenAI", "Microsoft Fabric", "Azure SQL", "SQL Server", "Azure DMS", "Next.js"],
      "imgSrc": "/images/project/6.png",
      "member": "4인 팀 프로젝트",
      "role": "Lead Database Engineer & Frontend Developer"
    },
    {
      "id": 5,
      "name": "실시간 고객 분석 및 RAG 기반 마케팅 시스템",
      "description": "실시간 고객 구매 데이터를 Event Hub와 Stream Analytics로 처리하여 즉각적인 마케팅 인사이트를 도출하고, Azure Functions와 RAG 기술을 활용해 자연어 질의응답 시스템을 구축했습니다.",
      "body": "### **1. 프로젝트 목표 및 해결 과제**\n\n기존의 배치(Batch) 처리 방식으로는 고객이 상품을 조회하거나 장바구니에 담는 '결정적 순간'에 즉각적으로 마케팅을 수행할 수 없었습니다. 이에 실시간으로 유입되는 로그를 분석하여 마케팅 골든타임을 확보하고, 마케터가 SQL을 몰라도 자연어로 데이터를 조회할 수 있는 환경을 구축하고자 했습니다.\n\n### **2. 기술적 구현**\n\n- **Real-time Pipeline:** Azure Event Hub로 유입되는 초당 수백 건의 클릭스트림 로그를 Stream Analytics로 실시간 처리하여 Cosmos DB(NoSQL)에 적재\n- **RAG System:** Azure OpenAI와 Azure AI Search를 연동하여, 사내 마케팅 매뉴얼 및 고객 데이터 기반의 질의응답 시스템(Chatbot) 구축\n- **Event Driven:** Azure Functions(Serverless)를 활용하여 특정 구매 패턴 감지 시 고객에게 쿠폰을 자동 발송하는 로직 구현\n\n### **3. 핵심 기여 및 트러블슈팅**\n\n**① RAG 모델의 환각(Hallucination) 현상 해결**\n- **문제:** LLM이 마케팅 정책에 없는 내용을 사실인 것처럼 답변하는 환각 현상이 발생했습니다.\n- **해결:** 프롬프트 엔지니어링을 통해 답변의 근거가 되는 문서(Context) 내에서만 대답하도록 제약 조건을 설정하고, 데이터 전처리 단계에서 불필요한 특수문자와 노이즈를 제거하여 검색 정확도를 높였습니다.\n\n**② 스트리밍 데이터 처리 지연(Latency) 최적화**\n- **문제:** 트래픽이 몰리는 시간대에 Stream Analytics의 처리 지연이 발생하여 실시간성이 떨어지는 문제가 있었습니다.\n- **해결:** 스트리밍 유닛(SU)을 확장하고, 텀블링 윈도우(Tumbling Window) 함수를 적절히 활용하여 집계 연산의 부하를 분산시켰습니다. 그 결과 데이터 발생부터 대시보드 반영까지의 지연 시간을 **초 단위(Sub-seconds)**로 유지할 수 있었습니다.",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2025. 07", "2025. 07"],
      "stack": ["Azure Data Factory", "Azure Machine Learning", "Azure OpenAI", "Cosmos DB", "Azure Functions", "Stream Analytics", "RAG"],
      "imgSrc": "/images/project/5.png",
      "member": "3인 팀 프로젝트",
      "role": "Real-time Pipeline & RAG Lead"
    },
    {
      "id": 4,
      "name": "Databricks 기반 BERT 개인화 영화 추천 시스템",
      "description": "협업 필터링과 콘텐츠 기반 필터링을 결합한 하이브리드 추천 시스템으로, 신규 유저의 콜드 스타트 문제를 해결하고 개인화된 추천을 제공했습니다.",
      "body": "### **1. 프로젝트 목표 및 해결 과제**\n\n기존의 협업 필터링(Collaborative Filtering) 방식은 데이터가 없는 신규 유저에게는 추천이 불가능한 **콜드 스타트(Cold Start)** 문제가 있었습니다. 이를 해결하기 위해 영화 줄거리(Text)를 분석하는 콘텐츠 기반 필터링을 결합하고, BERT 모델을 활용하여 맥락을 이해하는 정교한 하이브리드 추천 시스템을 개발하고자 했습니다.\n\n### **2. 기술적 구현**\n\n- **Big Data Processing:** Azure Databricks(Spark) 클러스터를 활용하여 대규모 영화 메타데이터 및 유저 평점 데이터 분산 처리\n- **Modeling:** BERT 모델로 영화 줄거리를 임베딩(Vectorization)하고, 코사인 유사도를 계산하여 콘텐츠 유사성 분석\n- **MLOps:** MLflow를 도입하여 모델 실험 이력(Experiment) 추적, 모델 버전 관리(Model Registry), 배포 파이프라인 자동화\n\n### **3. 핵심 기여 및 트러블슈팅**\n\n**① 모델 버전 관리의 혼선 해결 (MLflow)**\n- **문제:** 팀원들이 각자 로컬 환경에서 모델을 학습시키다 보니, 어떤 하이퍼파라미터가 최적의 성능을 냈는지 추적하기 어렵고 모델 파일 관리가 되지 않았습니다.\n- **해결:** **MLflow**를 도입하여 모든 실험의 파라미터와 메트릭(Accuracy, Loss)을 중앙 서버에 로깅하고, 성능이 가장 검증된 모델을 Registry에 등록하여 배포 과정을 표준화했습니다.\n\n**② 실시간 추천 API 응답 속도 개선**\n- **문제:** BERT 모델의 추론 연산량이 많아 실시간 추천 API의 응답 속도가 느렸습니다.\n- **해결:** 유저별 추천 결과(Top-N)를 미리 계산하여 **Redis 캐시**에 저장해두는 방식(Pre-computation)을 적용했습니다. 이를 통해 API 요청 시 실시간 연산 없이 캐시에서 즉시 결과를 반환하도록 하여 응답 속도를 획기적으로 단축했습니다.",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2025. 05", "2025. 05"],
      "stack": ["Databricks", "MLflow", "BERT", "Flask"],
      "imgSrc": "/images/project/4.png",
      "member": "6인 팀 프로젝트",
      "role": "PM & MLOps Engineer"
    },
    {
      "id": 3,
      "name": "권역 외상 센터 입지 선정 및 닥터헬기 필요성 분석",
      "description": "골든타임 확보가 시급한 중증 외상 환자를 위해 공간 데이터 분석(GIS)을 수행하고, P-Median 알고리즘으로 최적의 외상 센터 입지를 도출했습니다.",
      "body": "### **데이터 기반으로 생명을 살리는 최적의 입지를 제안했습니다.**\n\n- **공간 데이터(GIS) 분석 및 시각화**\n  - QGIS를 활용해 도로 네트워크, 인구 밀도, 기존 응급 의료 시설 위치 등 이종 데이터를 결합\n  - 응급 의료 취약 지역을 히트맵(Heatmap)으로 시각화하여 분석 대상 지역 선정\n\n- **입지 최적화 모델링**\n  - '모든 환자의 평균 이동 시간 최소화'를 목표 함수로 설정한 P-Median 모델 적용\n  - 최적화 솔버를 통해 기존 시설 대비 접근성이 획기적으로 개선되는 후보지 2곳 선정\n\n### **성과**\n- 기존 대비 평균 이송 시간 **15% 단축** 가능한 모델 제시\n- 공공 데이터 활용 경진대회 입상 (예시)",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2023. 03", "2023. 06"],
      "stack": ["R", "GIS", "Data Visualization"],
      "imgSrc": "/images/project/3.png",
      "member": "4인 팀 프로젝트",
      "role": "Data Analyst"
    },
    {
      "id": 2,
      "name": "무인판매점 도난방지 프로세스 개선 모델링",
      "description": "무인 매장의 도난 대응 프로세스를 분석하고, IoT 센서와 자동 알림 시스템을 도입하여 도난 대응 시간을 단축하는 TO-BE 프로세스를 설계했습니다.",
      "body": "### **프로세스 마이닝으로 운영 리스크를 줄였습니다.**\n\n- **AS-IS 프로세스 병목 분석**\n  - Bizagi를 활용해 기존의 수동적인 CCTV 모니터링 및 신고 절차를 모델링\n  - 도난 발생부터 신고까지 평균 3시간이 소요되는 문제점과 병목 구간 식별\n\n- **IoT 기반 자동화 프로세스(TO-BE) 설계**\n  - 매장 내 센서가 이상 행동 감지 시 경고 방송 송출 및 관리자 앱 알림 자동화\n  - 경찰 신고 연동 프로세스를 BPMN 표준으로 설계\n\n### **성과**\n- 도난 대응 예상 소요 시간 **70% 단축** 모델 제시\n- 24시간 모니터링 인력 비용 절감 효과 분석",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2022. 10", "2022. 11"],
      "stack": ["Bizagi", "Process Mining", "BPMN"],
      "imgSrc": "/images/project/2.png",
      "member": "4인 팀 프로젝트",
      "role": "Process Consultant"
    },
    {
      "id": 1,
      "name": "설문조사 기반 당뇨병 예측 ML 모델 구축",
      "description": "건강 검진 데이터를 활용하여 당뇨병 발병 위험을 예측하는 분류 모델입니다. SMOTE로 데이터 불균형을 해결하고 앙상블 기법으로 예측 성능을 높였습니다.",
      "body": "### **불균형 데이터를 극복하고 예측 성능을 높였습니다.**\n\n- **데이터 불균형 해결 (SMOTE)**\n  - 당뇨병 환자(Positive) 데이터가 적은 문제를 해결하기 위해 SMOTE 기법으로 소수 클래스 오버샘플링\n  - 모델이 다수 클래스(정상)에 편향되지 않도록 학습 데이터 균형 확보\n\n- **앙상블 모델링 및 튜닝**\n  - XGBoost와 Random Forest를 결합한 앙상블 모델 구축\n  - Grid Search로 최적의 하이퍼파라미터를 탐색하여 F1-Score 최적화\n\n### **성과**\n- 최종 모델 정확도 **92%** 달성\n- 주요 발병 요인(Feature Importance) 도출로 예방 가이드라인 제시",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2022. 10", "2022. 11"],
      "stack": ["Python", "Machine Learning", "Pandas"],
      "imgSrc": "/images/project/1.png",
      "member": "2인 팀 프로젝트",
      "role": "ML Engineer"
    },
    {
      "id": 0,
      "name": "중고 거래 플랫폼 DB 설계",
      "description": "대규모 트래픽을 고려하여 중고 거래 플랫폼의 데이터베이스를 설계했습니다. 제3정규형을 적용해 무결성을 확보하고 인덱스 최적화로 쿼리 성능을 높였습니다.",
      "body": "### **성능과 무결성을 고려한 RDB 설계 프로젝트입니다.**\n\n- **논리적/물리적 데이터베이스 모델링**\n  - 요구사항 분석을 통해 회원, 상품, 거래, 채팅 등 핵심 엔티티 도출\n  - 제3정규형(3NF)까지 정규화를 수행하여 데이터 중복 및 이상 현상(Anomaly) 방지\n\n- **쿼리 성능 최적화**\n  - '지역별 상품 검색', '카테고리 필터링' 등 빈번한 조회 쿼리를 분석하여 복합 인덱스(Composite Index) 설계\n  - 실행 계획(Execution Plan) 분석을 통해 Full Table Scan을 최소화\n\n### **성과**\n- 엔티티 20개 이상의 **ERD 설계 및 DDL 스크립트 작성**\n- 주요 비즈니스 시나리오에 대한 **SQL 쿼리 20종 검증**",
      "webUrl": "",
      "repoUrl": "",
      "isTeam": true,
      "period": ["2021. 10", "2021. 11"],
      "stack": ["SQL Server", "ERD", "Database Design"],
      "imgSrc": "/images/project/0.png",
      "member": "4인 팀 프로젝트",
      "role": "Database Architect"
    }
  ],
  "education": [
    { "id": 0, "name": "전남고등학교 졸업", "period": ["2014. 03", "2017. 02"] },
    { "id": 1, "name": "숭실대학교 산업정보시스템공학과 졸업", "period": ["2019. 03", "2025. 02"] },
    { "id": 2, "name": "Microsoft Data School 1기 수료", "period": ["2024. 01", "2024. 06"] }
  ],
  "certificate": [],
  "award": []
}