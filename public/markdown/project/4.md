# 🎬 BERT 기반 개인화 영화 추천 시스템

> <strong>"최신 NLP 기술을 추천 시스템에 도입하고, MLflow와 Flask를 연동하여 실제 서비스로 구현한 MLOps 프로젝트"</strong>

---

### 📑 목차 (Table of Contents)
1. [서비스 개요](#0-서비스-개요-service-overview)
2. [프로젝트 배경 및 목표](#1-프로젝트-배경-및-목표)
3. [시스템 아키텍처](#2-시스템-아키텍처-architecture)
4. [담당 역할 및 핵심 기여](#3-담당-역할-및-핵심-기여-my-contribution)
5. [프로젝트 성과 및 회고](#4-프로젝트-성과-및-회고-retrospective)

---

### 0. 서비스 개요 (Service Overview)

<strong>"나의 취향을 입력하면, AI가 맥락을 이해하고 영화를 추천합니다."</strong>

이 서비스는 사용자가 선호하는 영화를 입력하면, AI가 해당 영화들의 맥락(Context)을 분석하여 다음에 시청할 영화 10편을 추천해줍니다. 단순한 장르 매칭이 아니라, 사용자의 취향 시퀀스를 분석하여 정교한 추천 결과를 제공합니다.

![서비스 검색 및 추천 결과 화면](/images/project/4_service.png)
(▲ Flask로 구현된 영화 추천 웹 서비스 시연 화면)

<strong>[핵심 기능 Flow]</strong>
1. <strong>선호 입력:</strong> 사용자가 웹(Flask)에서 선호하는 영화를 검색하여 입력합니다.
2. <strong>실시간 추론:</strong> 입력된 영화 목록이 Databricks의 모델 서버로 전송되고, BERT 모델이 이를 분석합니다.
3. <strong>결과 매핑:</strong> 모델이 반환한 영화 ID를 TMDB API와 매핑하여 포스터, 줄거리 등 상세 정보와 함께 사용자에게 보여줍니다.

---

### 1. 프로젝트 배경 및 목표

<strong>[문제 정의: 풍요 속의 빈곤, '선택 피로']</strong>
OTT 시장의 폭발적인 성장으로 콘텐츠 수는 급증했지만, 사용자들은 여전히 "볼 게 없다"며 탐색에만 많은 시간을 허비하고 있습니다. 기존의 <strong>'인기 순위(Top 10)'</strong> 방식은 개인의 구체적인 취향을 반영하지 못해 만족도가 떨어지는 문제가 있었습니다.

<strong>[프로젝트 목표]</strong>
1. <strong>고성능 모델 도입:</strong> 최신 NLP 기술인 <strong>BERT</strong>를 추천 시스템에 적용하여, 사용자 행동의 '순서(Sequence)'와 '맥락'을 이해하는 모델 구축.
2. <strong>MLOps 파이프라인 구축:</strong> <strong>Azure Databricks</strong>와 <strong>MLflow</strong>를 활용하여 모델 실험부터 배포, 서빙까지의 과정을 파이프라인화.
3. <strong>End-to-End 서비스 구현:</strong> 단순 모델링을 넘어, 실제 사용자가 이용 가능한 웹 서비스(Flask)까지 완성.

---

### 2. 시스템 아키텍처 (Architecture)

![전체 시스템 아키텍처](/images/project/4_arch.png)
(▲ Azure Databricks와 Flask를 연동한 전체 시스템 아키텍처)

저는 이 프로젝트에서 <strong>PM(Project Manager)</strong>을 맡아 전체 일정을 조율하고, <strong>MLOps 엔지니어링</strong> 파트를 담당하여 모델과 웹 서비스를 연결하는 다리 역할을 수행했습니다.

---

### 3. 담당 역할 및 핵심 기여 (My Contribution)

#### (1) MLflow 기반 모델 서빙 및 API 구축
데이터 사이언스 팀이 개발한 모델을 실제 서비스에서 사용할 수 있도록 배포하는 과정을 전담했습니다.

![MLflow 서빙 로그](/images/project/4_serving.png)
(▲ MLflow Model Serving Endpoint 구성 및 로그)

* <strong>Serving Endpoint 구성:</strong> Databricks 내에 <strong>Model Serving Endpoint</strong>를 생성하여, 학습된 BERT 모델을 REST API 형태로 호출할 수 있는 환경을 구축했습니다.
* <strong>입출력 스키마 정의:</strong> 모델이 요구하는 텐서(Tensor) 입력 형태와 웹 서비스의 JSON 데이터 형식을 맞추기 위해 입출력 스키마를 정의하고 데이터 전처리 파이프라인을 연결했습니다.

#### (2) Flask 웹 서비스 연동 및 Full-Stack 구현
사용자 인터페이스(Front)부터 모델 추론 요청(Back)까지의 흐름을 구현했습니다.

* <strong>API 통신 로직 개발:</strong> Flask 백엔드에서 requests 라이브러리를 사용해 Databricks Serving Endpoint로 사용자의 선호 영화 데이터를 전송(POST)하고, 예측 결과를 받아오는 로직을 작성했습니다.
* <strong>TMDB API 매핑:</strong> 모델이 반환하는 추천 결과(MovieLens ID)를 사용자가 식별할 수 있는 포스터와 영화 정보로 변환하기 위해 외부 <strong>TMDB API</strong>와 연동했습니다.

#### (3) PM 및 협업 리딩
* <strong>역할 조율:</strong> 모델링 팀(3명)과 웹/데이터 엔지니어링 팀 간의 기술적 의존성을 파악하고, API 명세서를 정의하여 병렬 개발이 가능하도록 리딩했습니다.
* <strong>모델링 서포트:</strong> 팀원들이 모델 개발에 집중할 수 있도록 Databricks 클러스터 환경을 세팅하고, 모델 버전 관리(MLflow) 규칙을 수립하여 협업 효율을 높였습니다.

---

### 4. 프로젝트 성과 및 회고 (Retrospective)

<strong>[성과: 압도적인 추천 정확도 달성]</strong>
![모델 성능 비교표](/images/project/4_perf.png)
(▲ BERT 모델의 압도적인 성능 지표)

* 다양한 모델(ALS, XGBoost, Hybrid 등)을 실험한 결과, 시청 흐름을 학습한 BERT 모델이 <strong>Precision@10 0.86, Recall@10 0.86</strong>을 기록하며 기존 베이스라인 대비 획기적인 성능 향상을 이뤄냈습니다.

<strong>[PM으로서의 시행착오와 성장: "기계적 공평함의 함정"]</strong>
교육 과정의 첫 프로젝트였기에, 서먹한 팀 분위기를 풀고자 자연스럽게 PM을 맡게 되었습니다. 하지만 "모두가 배우는 과정"이라는 점을 과도하게 의식한 나머지, <strong>업무를 단순히 N분의 1로 공평하게 나누는 데에만 치중하는 실수</strong>를 범했습니다.

* <strong>문제:</strong> 역량을 고려하지 않은 배분은 프로젝트 속도 저하로 이어졌고, 팀원별 코드 퀄리티의 편차가 커서 통합 과정에서 예상보다 훨씬 많은 비용을 치러야 했습니다.
* <strong>깨달음:</strong> 이 경험을 통해 PM은 단순한 '배분자'가 아니라, <strong>팀원의 강점을 파악해 적재적소에 배치하는 '설계자'</strong>여야 함을 뼈저리게 느꼈습니다.
* <strong>개선:</strong> 이후 각자의 특기(모델링/웹/인프라)를 살린 <strong>역할 분담</strong>으로 신속히 체제를 개편했고, 결과적으로 BERT 모델 도입과 MLOps 파이프라인 구축이라는 도전적인 목표를 완수할 수 있었습니다.

---
<div style="display: flex; justify-content: space-between; margin-top: 50px;">
  <span style="color: #aaa;">🚫 이전 프로젝트 없음</span>
  <a href="/project/5" style="text-decoration: none; font-weight: bold; color: #333;">다음 프로젝트: 실시간 고객 분석 시스템 ➡️</a>
</div>