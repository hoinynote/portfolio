### **1. 프로젝트 개요**

![전체 시스템 아키텍처](/images/project/5_arch.png)
*(▲ 그림 1: 전체 시스템 아키텍처 - PDF 슬라이드 8)*

이커머스 환경에서 초단위로 발생하는 고객 구매 데이터를 실시간으로 수집·분석하여, 마케팅에 즉시 활용할 수 있는 인사이트를 제공하는 **지능형 마케팅 시스템**입니다. 기존의 배치(Batch) 처리 방식은 데이터 발생 후 분석까지 시차가 발생하여 즉각적인 고객 대응이 어렵다는 한계가 있었습니다. 이를 해결하기 위해 **Azure PaaS 기반의 실시간 데이터 파이프라인**을 구축하고, **RAG(검색 증강 생성)** 기술을 도입하여 데이터 기반의 자연어 질의응답 환경을 구현했습니다.

---

### **2. 데이터 및 분석 모델링**

![데이터 소개](/images/project/5_data.png)
*(▲ 그림 2-1: 사용 데이터셋 예시 - PDF 슬라이드 5)*

![모델링 결과](/images/project/5_modeling.png)
*(▲ 그림 2-2: GMM 클러스터링 분석 결과 - PDF 슬라이드 12)*

실제 커머스 환경을 모사하기 위해 공신력 있는 데이터를 활용하였으며, 단순한 통계를 넘어 머신러닝을 통해 고객을 정교하게 세분화했습니다.

#### **사용 데이터 (Data Source)**
* **Dataset:** UCI Machine Learning Repository의 **Online Retail Data**
* **규모:** 약 54만 건의 트랜잭션 데이터 (2011.12 ~ 2012.12)
* **구성:** 주문번호, 상품코드, 구매수량, 단가, 고객ID, 국가 등
* **실시간 시뮬레이션:** Flask 서버를 구축하여 이 데이터를 초당 수백 건씩 Azure Event Hub로 전송, 실제 쇼핑몰의 트래픽을 구현했습니다.

#### **분석 모델링: RFM & GMM Clustering**
고객의 가치를 정량화하기 위해 **RFM(Recency, Frequency, Monetary)** 분석을 수행하고, 이를 바탕으로 고객 군집화(Clustering)를 진행했습니다. 데이터 분포가 구형이 아닌 타원형을 띠는 특성을 반영하여, **Gaussian Mixture Model (GMM)**을 도입했습니다. [cite_start]이를 통해 경계에 있는 고객까지 유연하게 분류(Soft Clustering)하여 **'우수 VIP', '휴면 이탈', '중고가치 일반', '저가치 일반'**의 4개 그룹을 도출했습니다 [cite: 1493-1530].

---

### **3. 담당 역할: 실시간 파이프라인 & RAG 구축**

저는 이 프로젝트에서 **데이터 엔지니어링 및 백엔드 로직 전반**을 담당했습니다. Azure Portal에서 리소스를 직접 생성하고, 데이터가 흐르는 파이프라인의 핵심 로직을 구현했습니다.

#### **(1) 실시간 데이터 처리 (Stream Analytics & Cosmos DB)**

![실시간 데이터 흐름](/images/project/5_flow.png)
*(▲ 그림 3-1: 실시간 데이터 처리 파이프라인 흐름도 - PDF 슬라이드 20)*

![Stream Analytics 로직](/images/project/5_stream.png)
*(▲ 그림 3-2: Stream Analytics 쿼리 작성 화면 - PDF 슬라이드 22)*

**"초당 수백 건의 로그를 지연 없이 처리하다"**

Event Hub로 유입되는 원시(Raw) 로그 데이터를 실시간으로 정제하여 DB에 적재하는 파이프라인을 구축했습니다.
* [cite_start]**Azure Stream Analytics (ASA):** SQL 기반의 실시간 쿼리를 작성하여, 불필요한 필드를 제거하고 `CAST(Quantity AS float)`와 같이 데이터 타입을 검증/변환하는 전처리 로직을 수행했습니다 [cite: 842-921].
* **Azure Cosmos DB:** 가공된 데이터가 **NoSQL DB**에 실시간으로 적재되도록 구성하여, 스키마 유연성을 확보하고 대용량 쓰기(Write) 트래픽을 안정적으로 처리했습니다.

#### **(2) Serverless 기반 RFM 산출 (Azure Functions)**

![Azure Functions 로직](/images/project/5_function.png)
*(▲ 그림 4-1: Azure Functions 트리거 및 처리 코드 - PDF 슬라이드 24)*

![Cosmos DB 적재](/images/project/5_cosmos.png)
*(▲ 그림 4-2: Cosmos DB에 적재된 실시간 분석 결과 - PDF 슬라이드 26)*

**"이벤트 트리거를 통한 실시간 등급 갱신"**

데이터가 DB에 저장되는 순간을 포착하여 분석 로직을 실행하기 위해 **Azure Functions**를 활용했습니다.
* [cite_start]**Cosmos DB Trigger:** `realtime` 컨테이너에 새로운 구매 데이터가 들어오면(Change Feed) 즉시 함수가 실행되도록 트리거를 설정했습니다 [cite: 936-942].
* **로직 구현:** 파이썬(Python)으로 작성된 함수가 실행되면, 해당 고객의 **누적 구매액(Monetary), 최근 방문일(Recency), 빈도(Frequency)**를 재계산하고, 사전에 정의된 GMM 모델 기준에 따라 고객 등급을 실시간으로 업데이트합니다.

#### **(3) RAG(검색 증강 생성) 시스템 구축**

![RAG 아키텍처](/images/project/5_rag.png)
*(▲ 그림 5-1: RAG 데이터 임베딩 및 검색 흐름 - PDF 슬라이드 27)*

![RAG 질의응답](/images/project/5_rag_ex.png)
*(▲ 그림 5-2: RAG 기반 질의응답 실제 구현 화면 - PDF 슬라이드 29)*

**"데이터베이스와 LLM을 연결하여 문맥을 이해시키다"**

단순한 DB 조회를 넘어, LLM이 우리 데이터를 이해하고 답변할 수 있도록 **RAG 아키텍처**를 구현했습니다.
* **데이터 임베딩 (Embedding):** 갱신된 고객의 RFM 정보와 구매 내역을 자연어 텍스트로 변환한 후, **Embedding Model**을 통해 벡터화(Vectorization)하여 저장했습니다.
* **Context 주입:** 사용자가 질문을 던지면, 벡터 유사도 검색을 통해 가장 관련성 높은 고객 데이터를 찾아내고, 이를 GPT 프롬프트에 **Context**로 주입하여 할루시네이션(Hallucination) 없는 정확한 답변을 유도했습니다.

---

### **4. Trouble Shooting**

![트러블 슈팅](/images/project/5_trouble.png)
*(▲ 그림 6: 트러블 슈팅 요약 및 해결 방안 - PDF 슬라이드 42)*

#### **문제: RAG 검색 시 데이터 혼동 (Hallucination)**
RAG 시스템 초기 구축 시, 임베딩된 컬럼만을 사용하여 비교 질문을 했을 때 **요구한 레코드가 아닌 다른 고객의 데이터를 참조**하거나, 여러 고객의 정보가 뒤섞여 답변이 생성되는 문제가 발생했습니다. (예: "VIP 고객들의 특징은?"이라고 물었을 때, 일반 고객 데이터를 가져오는 현상)

#### **해결: 2단계 프롬프트 필터링 전략**
벡터 검색의 한계를 보완하기 위해, 질문의 의도를 파악하여 검색 범위를 물리적으로 제한하는 로직을 추가했습니다.

1.  **1차 필터링 (Intent Extraction):** 사용자의 질문에서 '고객 ID(예: 14305)' 혹은 '등급(예: VIP)' 키워드가 있는지 먼저 추출합니다.
2.  **프롬프트 분기 (Prompt Branching):** 추출된 메타데이터를 기반으로 **목적에 따른 프롬프트**로 분류되도록 설계했습니다. 특정 ID가 감지되면 해당 ID의 데이터만 검색 범위로 한정한 뒤 답변을 생성하도록 강제했습니다.

#### **결과**
이 로직 적용 후, 특정 고객이나 등급에 대한 비교 분석 질문 시 **정확히 해당 범위 내의 데이터만 참조**하게 되어 답변의 신뢰도를 크게 향상시켰습니다.